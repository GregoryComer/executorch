


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Arm Ethos-U Backend &mdash; ExecuTorch main documentation</title>
  

  
  
    <link rel="shortcut icon" href="_static/ExecuTorch-Logo-cropped.svg"/>
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="_static/progress-bar.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />


  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  


  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2024">
                  <span class="dropdown-title">Contributor Awards - 2024</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch/stable/index.html">
                  <span class="dropdown-title">ExecuTorch Docs</span>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/newsletter">
                  <span class="dropdown-title">Newsletter</span>
                  <p>Stay up-to-date with the latest updates</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/credits">
                  <span class="dropdown-title">Cloud Credit Program</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tac">
                  <span class="dropdown-title">Technical Advisory Council</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/staff">
                  <span class="dropdown-title">Staff</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/contact-us">
                  <span class="dropdown-title">Contact Us</span>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/executorch/versions.html'>main &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          
    
         
         
         
              <p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="intro-overview.html">ExecuTorch Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro-how-it-works.html">How ExecuTorch Works</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting-started-architecture.html">Architecture and Components</a></li>
<li class="toctree-l1"><a class="reference internal" href="concepts.html">Concepts</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="getting-started.html">Getting Started with ExecuTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="using-executorch-export.html">Model Export and Lowering</a></li>
<li class="toctree-l1"><a class="reference internal" href="using-executorch-android.html">Using ExecuTorch on Android</a></li>
<li class="toctree-l1"><a class="reference internal" href="using-executorch-ios.html">Using ExecuTorch on iOS</a></li>
<li class="toctree-l1"><a class="reference internal" href="using-executorch-cpp.html">Using ExecuTorch with C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="using-executorch-runtime-integration.html">Runtime Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="using-executorch-troubleshooting.html">Profiling and Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="using-executorch-building-from-source.html">Building from Source</a></li>
<li class="toctree-l1"><a class="reference internal" href="using-executorch-faqs.html">Frequently Asked Questions</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/pytorch-labs/executorch-examples/tree/main/dl3/android/DeepLabV3Demo#executorch-android-demo-app">Building an ExecuTorch Android Demo App</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo-apps-ios.html">Building an ExecuTorch iOS Demo App</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Backends</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="backends-overview.html">Backend Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="backends-xnnpack.html">XNNPACK Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="backends-coreml.html">Core ML Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="backends-mps.html">MPS Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="backends-vulkan.html">Vulkan Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="backends-arm-ethos-u.html">Arm(R) Ethos(TM)-U NPU Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="backends-qualcomm.html">Qualcomm AI Engine Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="backends-mediatek.html">MediaTek Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="backends-cadence.html">Cadence Xtensa Backend</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Tools</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="devtools-overview.html">Introduction to the ExecuTorch Developer Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="bundled-io.html">Bundled Program – a Tool for ExecuTorch Model Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="etrecord.html">Prerequisite | ETRecord - ExecuTorch Record</a></li>
<li class="toctree-l1"><a class="reference internal" href="etdump.html">Prerequisite | ETDump - ExecuTorch Dump</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime-profiling.html">Profiling Models in ExecuTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="model-debugging.html">Debugging Models in ExecuTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="model-inspector.html">Inspector APIs</a></li>
<li class="toctree-l1"><a class="reference internal" href="memory-planning-inspection.html">Memory Planning Inspection in ExecuTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="delegate-debugging.html">Delegate Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="devtools-tutorial.html">Developer Tools Usage Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Runtime</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="runtime-overview.html">ExecuTorch Runtime Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="extension-module.html">Running an ExecuTorch Model Using the Module Extension in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="extension-tensor.html">Managing Tensor Memory in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="running-a-model-cpp-tutorial.html">Running an ExecuTorch Model in C++ Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime-backend-delegate-implementation-and-linking.html">Backend Delegate Implementation and Linking</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime-platform-abstraction-layer.html">Runtime Platform Abstraction Layer (PAL)</a></li>
<li class="toctree-l1"><a class="reference internal" href="portable-cpp-programming.html">Portable C++ Programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="pte-file-format.html"><code class="docutils literal notranslate"><span class="pre">.pte</span></code> file format</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="export-to-executorch-api-reference.html">Export API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="executorch-runtime-api-reference.html">Runtime API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="runtime-python-api-reference.html">Runtime Python API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="api-life-cycle.html">API Life Cycle and Deprecation Policy</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/executorch/main/javadoc/">Javadoc</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Quantization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quantization-overview.html">Quantization Overview</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Kernel Library</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="kernel-library-overview.html">Overview of ExecuTorch’s Kernel Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="kernel-library-custom-aten-kernel.html">Kernel Registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="kernel-library-selective-build.html">Kernel Library Selective Build</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Working with LLMs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="llm/llama.html">Llama</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm/llama-demo-android.html">Llama on Android</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm/llama-demo-ios.html">Llama on iOS</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm/build-run-llama3-qualcomm-ai-engine-direct-backend.html">Llama on Android via Qualcomm backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="llm/getting-started.html">Intro to LLMs in Executorch</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Backend Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="backend-delegates-integration.html">Integrating a Backend Delegate into ExecuTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="backend-delegates-xnnpack-reference.html">XNNPACK Delegate Internals</a></li>
<li class="toctree-l1"><a class="reference internal" href="backend-delegates-dependencies.html">Third-Party Dependency Management for Backend Delegates</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiler-delegate-and-partitioner.html">Backends and Delegates</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug-backend-delegate.html">Debugging Delegation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">IR Specification</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="ir-exir.html">Export IR Specification</a></li>
<li class="toctree-l1"><a class="reference internal" href="ir-ops-set-definition.html">Definition of the Core ATen Operator Set</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Compiler Entry Points</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="compiler-backend-dialect.html">Backend Dialect</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiler-custom-compiler-passes.html">Custom Compiler Passes and Partitioners</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiler-memory-planning.html">Memory Planning</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contributing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing to ExecuTorch</a></li>
</ul>

         

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Arm Ethos-U Backend</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/tutorial-arm-ethos-u.md.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        


          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <!---- Name is a WIP - this reflects better what it can do today ----->
<div class="section" id="arm-ethos-u-backend">
<h1>Arm Ethos-U Backend<a class="headerlink" href="#arm-ethos-u-backend" title="Permalink to this heading">¶</a></h1>
<!----This will show a grid card on the page----->
<div class="sd-container-fluid sd-sphinx-override sd-mb-4 docutils">
<div class="sd-row sd-row-cols-2 sd-row-cols-xs-2 sd-row-cols-sm-2 sd-row-cols-md-2 sd-row-cols-lg-2 docutils">
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm card-prerequisites docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
Tutorials we recommend you complete before this:</div>
<ul class="simple">
<li><p class="sd-card-text"><a class="reference internal" href="intro-how-it-works.html"><span class="doc std std-doc">Introduction to ExecuTorch</span></a></p></li>
<li><p class="sd-card-text"><a class="reference internal" href="getting-started.html"><span class="doc std std-doc">Getting Started</span></a></p></li>
<li><p class="sd-card-text"><a class="reference internal" href="using-executorch-building-from-source.html"><span class="doc std std-doc">Building ExecuTorch with CMake</span></a></p></li>
</ul>
</div>
</div>
</div>
<div class="sd-col sd-d-flex-row docutils">
<div class="sd-card sd-sphinx-override sd-w-100 sd-shadow-sm card-prerequisites docutils">
<div class="sd-card-body docutils">
<div class="sd-card-title sd-font-weight-bold docutils">
What you will learn in this tutorial:</div>
<p class="sd-card-text">In this tutorial you will learn how to export a simple PyTorch model for ExecuTorch Arm Ethos-U backend delegate and run it on a Corstone FVP emulators.</p>
</div>
</div>
</div>
</div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This ExecuTorch backend delegate is under active development. You may encounter some rough edges and features which may be documented or planned but not implemented.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If you are already familiar with this delegate, you may want to jump directly to the examples source dir - <a class="reference external" href="https://github.com/pytorch/executorch/tree/main/examples/arm">https://github.com/pytorch/executorch/tree/main/examples/arm</a></p>
</div>
<div class="section" id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this heading">¶</a></h2>
<p>Let’s make sure you have everything you need before you get started.</p>
<div class="section" id="hardware">
<h3>Hardware<a class="headerlink" href="#hardware" title="Permalink to this heading">¶</a></h3>
<p>To successfully complete this tutorial, you will need a Linux-based host machine with Arm aarch64 or x86_64 processor architecture.</p>
<p>The target device will be an embedded platform with an Arm Cortex-M CPUs and Ethos-U NPUs (ML processor). This tutorial will show you how to run PyTorch models on both.</p>
<p>We will be using a <a class="reference external" href="https://www.arm.com/products/development-tools/simulation/fixed-virtual-platforms">Fixed Virtual Platform (FVP)</a>, simulating <a class="reference external" href="https://developer.arm.com/Processors/Corstone-300">Corstone-300</a>(cs300) and <a class="reference external" href="https://developer.arm.com/Processors/Corstone-320">Corstone-320</a>(cs320)systems. Since we will be using the FVP (think of it as virtual hardware), we won’t be requiring any real embedded hardware for this tutorial.</p>
</div>
<div class="section" id="software">
<h3>Software<a class="headerlink" href="#software" title="Permalink to this heading">¶</a></h3>
<p>First, you will need to install ExecuTorch. Please follow the recommended tutorials if you haven’t already, to set up a working ExecuTorch development environment.</p>
<p>To generate software which can be run on an embedded platform (real or virtual), we will need a tool chain for cross-compilation and an Arm Ethos-U software development kit, including the Vela compiler for Ethos-U NPUs.</p>
<p>In the following sections we will walk through the steps to download each of the dependencies listed above.</p>
</div>
</div>
<div class="section" id="set-up-the-developer-environment">
<h2>Set Up the Developer Environment<a class="headerlink" href="#set-up-the-developer-environment" title="Permalink to this heading">¶</a></h2>
<p>In this section, we will do a one-time setup, like downloading and installing necessary software, for the platform support files needed to run ExecuTorch programs in this tutorial.</p>
<p>For that we will use the <code class="docutils literal notranslate"><span class="pre">examples/arm/setup.sh</span></code> script to pull each item in an automated fashion. It is recommended to run the script in a conda environment. Upon successful execution, you can directly go to <a class="reference internal" href="#convert-the-pytorch-model-to-the-pte-file"><span class="std std-doc">the next step</span></a>.</p>
<p>As mentioned before, we currently support only Linux based platforms with x86_64 or aarch64 processor architecture. Let’s make sure we are indeed on a supported platform.</p>
<div class="highlight-none notranslate highlight-bash"><div class="highlight"><pre><span></span>uname<span class="w"> </span>-s
<span class="c1"># Linux</span>

uname<span class="w"> </span>-m
<span class="c1"># x86_64 or aarch64</span>
</pre></div>
</div>
<p>Next we will walk through the steps performed by the <code class="docutils literal notranslate"><span class="pre">setup.sh</span></code> script to better understand the development setup.</p>
<div class="section" id="download-and-set-up-the-corstone-300-and-corstone-320-fvp">
<h3>Download and Set Up the Corstone-300 and Corstone-320 FVP<a class="headerlink" href="#download-and-set-up-the-corstone-300-and-corstone-320-fvp" title="Permalink to this heading">¶</a></h3>
<p>Fixed Virtual Platforms (FVPs) are pre-configured, functionally accurate simulations of popular system configurations. Here in this tutorial, we are interested in Corstone-300 and Corstone-320 systems. We can download this from the Arm website.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>By downloading and running the FVP software, you will be agreeing to the FVP <a class="reference external" href="https://developer.arm.com/downloads/-/arm-ecosystem-fvps/eula">End-user license agreement (EULA)</a>.</p>
</div>
<p>To download, we can either download <code class="docutils literal notranslate"><span class="pre">Corstone-300</span> <span class="pre">Ecosystem</span> <span class="pre">FVP</span></code> and <code class="docutils literal notranslate"><span class="pre">Corstone-320</span> <span class="pre">Ecosystem</span> <span class="pre">FVP</span></code>from <a class="reference external" href="https://developer.arm.com/downloads/-/arm-ecosystem-fvps">here</a>. or <code class="docutils literal notranslate"><span class="pre">setup.sh</span></code> script does that for you under <code class="docutils literal notranslate"><span class="pre">setup_fvp</span></code> function.</p>
</div>
<div class="section" id="download-and-install-the-arm-gnu-aarch32-bare-metal-toolchain">
<h3>Download and Install the Arm GNU AArch32 Bare-Metal Toolchain<a class="headerlink" href="#download-and-install-the-arm-gnu-aarch32-bare-metal-toolchain" title="Permalink to this heading">¶</a></h3>
<p>Similar to the FVP, we would also need a tool-chain to cross-compile ExecuTorch runtime, executor-runner bare-metal application, as well as the rest of the bare-metal stack for Cortex-M55/M85 CPU available on the Corstone-300/Corstone-320 platform.</p>
<p>These toolchains are available <a class="reference external" href="https://developer.arm.com/downloads/-/arm-gnu-toolchain-downloads">here</a>. We will be using GCC 13.3.rel1 targeting <code class="docutils literal notranslate"><span class="pre">arm-none-eabi</span></code> here for our tutorial. Just like FVP, <code class="docutils literal notranslate"><span class="pre">setup.sh</span></code> script will down the toolchain for you. See <code class="docutils literal notranslate"><span class="pre">setup_toolchain</span></code> function.</p>
</div>
<div class="section" id="setup-the-arm-ethos-u-software-development">
<h3>Setup the Arm Ethos-U Software Development<a class="headerlink" href="#setup-the-arm-ethos-u-software-development" title="Permalink to this heading">¶</a></h3>
<p>This git repository is the root directory for all Arm Ethos-U software. It is to help us download required repositories and place them in a tree structure. See <code class="docutils literal notranslate"><span class="pre">setup_ethos_u</span></code> function of the setup script for more details.</p>
<p>Once this is done, you should have a working FVP simulator, a functioning toolchain for cross compilation, and the Ethos-U software development setup ready for the bare-metal developement.</p>
</div>
<div class="section" id="install-the-vela-compiler">
<h3>Install the Vela Compiler<a class="headerlink" href="#install-the-vela-compiler" title="Permalink to this heading">¶</a></h3>
<p>Once this is done, the script will finish the setup by installing the Vela compiler for you, details are in <code class="docutils literal notranslate"><span class="pre">setup_vela</span></code> function.</p>
</div>
<div class="section" id="install-the-tosa-reference-model">
<h3>Install the TOSA reference model<a class="headerlink" href="#install-the-tosa-reference-model" title="Permalink to this heading">¶</a></h3>
<p>This is the last step of the setup process, using <code class="docutils literal notranslate"><span class="pre">setup_tosa_reference_model</span></code> function <code class="docutils literal notranslate"><span class="pre">setup.sh</span></code> script will install TOSA reference model for you.</p>
<p>At the end of the setup, if everything goes well, your top level devlopement dir might look something like this,</p>
<div class="highlight-none notranslate highlight-bash"><div class="highlight"><pre><span></span>.
├──<span class="w"> </span>arm-gnu-toolchain-13.3.rel1-x86_64-arm-none-eabi<span class="w"> </span><span class="c1"># for x86-64 hosts</span>
├──<span class="w"> </span>arm-gnu-toolchain-13.3.rel1-x86_64-arm-none-eabi.tar.xz
├──<span class="w"> </span>ethos-u
│<span class="w">   </span>├──<span class="w"> </span>core_platform
│<span class="w">   </span>├──<span class="w"> </span>core_software
│<span class="w">   </span>├──<span class="w"> </span>fetch_externals.py
│<span class="w">   </span>└──<span class="w"> </span><span class="o">[</span>...<span class="o">]</span>
├──<span class="w"> </span>FVP-corstone300
│<span class="w">   </span>├──<span class="w"> </span>FVP_Corstone_SSE-300.sh
│<span class="w">   </span>└──<span class="w"> </span><span class="o">[</span>...<span class="o">]</span>
├──<span class="w"> </span>FVP-corstone320
│<span class="w">   </span>├──<span class="w"> </span>FVP_Corstone_SSE-320.sh
│<span class="w">   </span>└──<span class="w"> </span><span class="o">[</span>...<span class="o">]</span>
├──<span class="w"> </span>FVP_corstone300.tgz
├──<span class="w"> </span>FVP_corstone320.tgz
└──<span class="w"> </span>setup_path.sh
</pre></div>
</div>
</div>
<div class="section" id="notes">
<h3>Notes:<a class="headerlink" href="#notes" title="Permalink to this heading">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">setup.sh</span></code> script has generated a <code class="docutils literal notranslate"><span class="pre">setup_path.sh</span></code> script that you need to source everytime you restart you shell.</p>
<p>e.g. run
<code class="docutils literal notranslate"><span class="pre">source</span>&#160; <span class="pre">executorch/examples/arm/ethos-u-scratch/setup_path.sh</span></code></p>
<p>As <code class="docutils literal notranslate"><span class="pre">setup.sh</span></code> will download and setup the needed Arm toolchain make sure it is used by calling</p>
<p><code class="docutils literal notranslate"><span class="pre">which</span> <span class="pre">arm-none-eabi-gcc</span></code></p>
<p>It should show <code class="docutils literal notranslate"><span class="pre">arm-none-eabi-gcc</span></code> in the <code class="docutils literal notranslate"><span class="pre">executorch</span></code> project and not anything in <code class="docutils literal notranslate"><span class="pre">/usr/bin</span></code> something like:</p>
<p><code class="docutils literal notranslate"><span class="pre">&lt;EXECUTORCH_ROOT&gt;/examples/arm/ethos-u-scratch/arm-gnu-toolchain-13.3.rel1-aarch64-arm-none-eabi/bin/arm-none-eabi-gcc</span></code>
or
<code class="docutils literal notranslate"><span class="pre">&lt;EXECUTORCH_ROOT&gt;/examples/arm/ethos-u-scratch/arm-gnu-toolchain-13.3.rel1-x86_64-arm-none-eabi/bin/arm-none-eabi-gcc</span></code></p>
<p>If not you might need to uninstall <code class="docutils literal notranslate"><span class="pre">arm-none-eabi-gcc</span></code> or make sure its picked after the one in the project in your $PATH env varable.</p>
</div>
</div>
<div class="section" id="convert-the-pytorch-model-to-the-pte-file">
<h2>Convert the PyTorch Model to the <code class="docutils literal notranslate"><span class="pre">.pte</span></code> File<a class="headerlink" href="#convert-the-pytorch-model-to-the-pte-file" title="Permalink to this heading">¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">.pte</span></code> is a binary file produced by ExecuTorch Ahead-of-Time (AoT) pipeline by taking in a PyTorch Model (a torch.nn.Module), exporting it, running a variety of passes, and finally serializing it to a <code class="docutils literal notranslate"><span class="pre">.pte</span></code> file format. This binary file is typically consumed by the ExecuTorch Runtime. This <a class="reference external" href="https://github.com/pytorch/executorch/blob/main/docs/source/getting-started-architecture.md">document</a> goes in much more depth about the ExecuTorch software stack for both AoT as well as Runtime.</p>
<p>In this section, we will primarily focus on the AoT flow with the end goal of producing a <code class="docutils literal notranslate"><span class="pre">.pte</span></code> file. There are a set of export configurations to target different backends at runtime. For each, the AoT flow will produce a unique <code class="docutils literal notranslate"><span class="pre">.pte</span></code> file. We will explore a couple of different configurations producing different <code class="docutils literal notranslate"><span class="pre">.pte</span></code> files, particularly interesting for our Corstone-300 system and available processing elements.</p>
<p>Before we get started, let’s first talk about the PyTorch modules we will be using.</p>
<div class="section" id="pytorch-example-modules">
<h3>PyTorch Example Modules<a class="headerlink" href="#pytorch-example-modules" title="Permalink to this heading">¶</a></h3>
<p>We will use a couple of simple PyTorch Modules to explore the end-to-end flow. These modules will be used in various different ways throughout the tutorial, referring to them by their <code class="docutils literal notranslate"><span class="pre">&lt;class_name&gt;</span></code>.</p>
<div class="section" id="softmaxmodule">
<h4>SoftmaxModule<a class="headerlink" href="#softmaxmodule" title="Permalink to this heading">¶</a></h4>
<p>This is a very simple PyTorch module with just one <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html#torch.nn.Softmax">Softmax</a> operator.</p>
<div class="highlight-none notranslate highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="k">class</span><span class="w"> </span><span class="nc">SoftmaxModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span>
</pre></div>
</div>
<p>Running it using the Python environment (on the same development Linux machine), you get the expected output.</p>
<div class="highlight-none notranslate highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">SoftmaxModule</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="go">tensor([[0.5000, 0.5000],</span>
<span class="go">        [0.5000, 0.5000]])</span>
</pre></div>
</div>
</div>
<div class="section" id="addmodule">
<h4>AddModule<a class="headerlink" href="#addmodule" title="Permalink to this heading">¶</a></h4>
<p>Let’s write another simple PyTorch module with just one <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.add.html#torch.add">Add</a> operator.</p>
<div class="highlight-none notranslate highlight-python"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">AddModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">x</span>
</pre></div>
</div>
<p>Running it in python shows that 1 + 1 produces 2 as exepected:</p>
<div class="highlight-none notranslate highlight-python"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">AddModule</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">))</span> <span class="c1"># integer types for non-quantized Ethos-U delegation</span>
<span class="go">tensor([2, 2, 2, 2, 2], dtype=torch.int32)</span>
</pre></div>
</div>
<p>Keep the inputs and outputs to these modules in mind. When you will lower and run this through alternate means as opposed to running on this Linux machine, you will use the same inputs, and expect the outputs to match with the one shown here.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>you need to be aware of data types for running networks on the Ethos-U as it is an integer only co-processor. For this example you use integer types explicitly, for typical use of such a flow networks are built and trained in floating point, and then are quantized from floating point to integer for efficient inference.</p>
</div>
</div>
<div class="section" id="mobilenetv2-module">
<h4>MobileNetV2 Module<a class="headerlink" href="#mobilenetv2-module" title="Permalink to this heading">¶</a></h4>
<p><a class="reference external" href="https://arxiv.org/abs/1801.04381">MobileNetV2</a> is a commonly used network for edge and mobile devices.
It’s also available as a default model in <a class="reference external" href="https://github.com/pytorch/vision">torchvision</a>, so you can load it with the sample code below.</p>
<div class="highlight-none notranslate highlight-default"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">mobilenet_v2</span>  <span class="c1"># @manual</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.models.mobilenetv2</span><span class="w"> </span><span class="kn">import</span> <span class="n">MobileNet_V2_Weights</span>

<span class="n">mv2</span> <span class="o">=</span> <span class="n">mobilenet_v2</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="n">MobileNet_V2_Weights</span><span class="o">.</span><span class="n">DEFAULT</span><span class="p">)</span>
</pre></div>
</div>
<p>For more details, refer to the code snippet <a class="reference external" href="https://github.com/pytorch/executorch/blob/2354945d47f67f60d9a118ea1a08eef8ba2364b5/examples/models/mobilenet_v2/model.py#L18">here</a>.</p>
</div>
</div>
<div class="section" id="non-delegated-workflow">
<h3>Non-delegated Workflow<a class="headerlink" href="#non-delegated-workflow" title="Permalink to this heading">¶</a></h3>
<p>In the ExecuTorch AoT pipeline, one of the options is to select a backend. ExecuTorch offers a variety of different backends. Selecting backend is optional, it is typically done to target a particular mode of acceleration or hardware for a given model compute requirements. Without any backends, ExecuTorch runtime will fallback to using, available by default, a highly portable set of operators.</p>
<p>It’s expected that on platforms with dedicated acceleration like the Ethos-U55, that the non-delegated flow is used for two primary cases:</p>
<ol class="arabic simple">
<li><p>When the network is designed to be very small and best suited to run on the Cortex-M alone.</p></li>
<li><p>When the network has a mix of operations that can target the NPU and those that can’t, e.g. the Ethos-U55 supports integer operations and so floating point softmax will fall back to execute on the CPU.</p></li>
</ol>
<p>In this flow, without any backend delegates, to illustrate the portability of the ExecuTorch runtime, as well as of the operator library you will skip specifying the backend during the <code class="docutils literal notranslate"><span class="pre">.pte</span></code> generation.</p>
<p>Following script will serve as a helper utility to help generating the <code class="docutils literal notranslate"><span class="pre">.pte</span></code> file. This is available in the <code class="docutils literal notranslate"><span class="pre">examples/arm</span></code> directory.</p>
<div class="highlight-none notranslate highlight-bash"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>examples.arm.aot_arm_compiler<span class="w"> </span>--model_name<span class="o">=</span><span class="s2">&quot;softmax&quot;</span>
<span class="c1"># This should produce ./softmax_arm_ethos-u55-128.pte</span>
</pre></div>
</div>
</div>
<div class="section" id="delegated-workflow">
<h3>Delegated Workflow<a class="headerlink" href="#delegated-workflow" title="Permalink to this heading">¶</a></h3>
<p>Working with Arm, you introduced a new Arm backend delegate for ExecuTorch. This backend is under active development and has a limited set of features available as of writing this.</p>
<p>By including a following step during the ExecuTorch AoT export pipeline to generate the <code class="docutils literal notranslate"><span class="pre">.pte</span></code> file, you can enable this backend delegate.</p>
<div class="highlight-none notranslate highlight-python"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">executorch.backends.arm.arm_backend</span><span class="w"> </span><span class="kn">import</span> <span class="n">generate_ethosu_compile_spec</span>

<span class="n">graph_module_edge</span><span class="o">.</span><span class="n">exported_program</span> <span class="o">=</span> <span class="n">to_backend</span><span class="p">(</span>
    <span class="n">model</span><span class="o">.</span><span class="n">exported_program</span><span class="p">,</span>
    <span class="n">ArmPartitioner</span><span class="p">(</span><span class="n">generate_ethosu_compile_spec</span><span class="p">(</span><span class="s2">&quot;ethos-u55-128&quot;</span><span class="p">)))</span>
</pre></div>
</div>
<p>Similar to the non-delegate flow, the same script will server as a helper utility to help generate the <code class="docutils literal notranslate"><span class="pre">.pte</span></code> file. Notice the <code class="docutils literal notranslate"><span class="pre">--delegate</span></code> option to enable the <code class="docutils literal notranslate"><span class="pre">to_backend</span></code> call.</p>
<div class="highlight-none notranslate highlight-bash"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>examples.arm.aot_arm_compiler<span class="w"> </span>--model_name<span class="o">=</span><span class="s2">&quot;add&quot;</span><span class="w"> </span>--delegate
<span class="c1"># should produce ./add_arm_delegate_ethos-u55-128.pte</span>
</pre></div>
</div>
</div>
<div class="section" id="delegated-quantized-workflow">
<h3>Delegated Quantized Workflow<a class="headerlink" href="#delegated-quantized-workflow" title="Permalink to this heading">¶</a></h3>
<p>Before generating the <code class="docutils literal notranslate"><span class="pre">.pte</span></code> file for delegated quantized networks like MobileNetV2, you need to build the <code class="docutils literal notranslate"><span class="pre">quantized_ops_aot_lib</span></code></p>
<p>You can just run the <code class="docutils literal notranslate"><span class="pre">backends/arm/scripts/build_quantized_ops_aot_lib.sh</span></code> script to build this for you or build it yourself like this.</p>
<div class="highlight-none notranslate highlight-bash"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>&lt;executorch_root_dir&gt;
mkdir<span class="w"> </span>-p<span class="w"> </span>cmake-out-aot-lib
cmake<span class="w"> </span>-DCMAKE_BUILD_TYPE<span class="o">=</span>Release<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-DEXECUTORCH_BUILD_XNNPACK<span class="o">=</span>OFF<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-DEXECUTORCH_BUILD_KERNELS_QUANTIZED<span class="o">=</span>ON<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-DEXECUTORCH_BUILD_KERNELS_QUANTIZED_AOT<span class="o">=</span>ON<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-DPYTHON_EXECUTABLE<span class="o">=</span>python3<span class="w"> </span><span class="se">\</span>
-Bcmake-out-aot-lib<span class="w"> </span><span class="se">\</span>
<span class="w">    </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">et_root_dir</span><span class="si">}</span><span class="s2">&quot;</span>

cmake<span class="w"> </span>--build<span class="w"> </span>cmake-out-aot-lib<span class="w"> </span>--parallel<span class="w"> </span>--<span class="w"> </span>quantized_ops_aot_lib
</pre></div>
</div>
<p>After the <code class="docutils literal notranslate"><span class="pre">quantized_ops_aot_lib</span></code> build, you can run the following script to generate the <code class="docutils literal notranslate"><span class="pre">.pte</span></code> file</p>
<div class="highlight-none notranslate highlight-bash"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>examples.arm.aot_arm_compiler<span class="w"> </span>--model_name<span class="o">=</span><span class="s2">&quot;mv2&quot;</span><span class="w"> </span>--delegate<span class="w"> </span>--quantize<span class="w"> </span>--so_library<span class="o">=</span><span class="s2">&quot;</span><span class="k">$(</span>find<span class="w"> </span>cmake-out-aot-lib<span class="w"> </span>-name<span class="w"> </span>libquantized_ops_aot_lib.so<span class="k">)</span><span class="s2">&quot;</span>
<span class="c1"># should produce ./mv2_arm_delegate_ethos-u55-128.pte</span>
</pre></div>
</div>
<br />
<p>At the end of this, you should have three different <code class="docutils literal notranslate"><span class="pre">.pte</span></code> files.</p>
<ul class="simple">
<li><p>The first one contains the <a class="reference internal" href="#softmaxmodule"><span class="std std-doc">SoftmaxModule</span></a>, without any backend delegates.</p></li>
<li><p>The second one contains the <a class="reference internal" href="#addmodule"><span class="std std-doc">AddModule</span></a>, with Arm Ethos-U backend delegate enabled.</p></li>
<li><p>The third one contains the <span class="xref myst">quantized MV2Model</span>, with the Arm Ethos-U backend delegate enabled as well.</p></li>
</ul>
<p>Now let’s try to run these <code class="docutils literal notranslate"><span class="pre">.pte</span></code> files on a Corstone-300 and Corstone-320 platforms in a bare-metal environment.</p>
</div>
</div>
<div class="section" id="getting-a-bare-metal-executable">
<h2>Getting a Bare-Metal Executable<a class="headerlink" href="#getting-a-bare-metal-executable" title="Permalink to this heading">¶</a></h2>
<p>In this section, you will go over steps that you need to go through to build the runtime application. This then run on the target device. In the executorch repository you have a functioning script which does the exact same steps. It is located at <code class="docutils literal notranslate"><span class="pre">executorch/examples/arm/run.sh</span></code>. You will use that to build necessary pieces and finally run the previously generated PTE file on an FVP.</p>
<p>By default the <code class="docutils literal notranslate"><span class="pre">run.sh</span></code> will use <code class="docutils literal notranslate"><span class="pre">arm_test/</span></code> as an build and output folder and you will find the build artifacts under it. This can be contolled/overrided with the <code class="docutils literal notranslate"><span class="pre">--et_build_root</span></code> and the <code class="docutils literal notranslate"><span class="pre">--output</span></code> flags if needed.</p>
<p>e.g. running <code class="docutils literal notranslate"><span class="pre">examples/arm/run.sh</span> <span class="pre">--model_name=add</span> <span class="pre">--target=ethos-u85-128</span></code> will produce a pte and elf file like this:</p>
<div class="highlight-none notranslate highlight-bash"><div class="highlight"><pre><span></span>arm_test/add/add_arm_delegate_ethos-u85-128.pte
arm_test/add/cmake-out/arm_executor_runner
</pre></div>
</div>
<p>Also before you get started, make sure that you have completed ExecuTorch cmake build setup, and the instructions to setup the development environment described <a class="reference internal" href="#set-up-the-developer-environment"><span class="std std-doc">earlier</span></a>.</p>
<p>The block diagram below demonstrates, at the high level, how the various build artifacts are generated and are linked together to generate the final bare-metal executable.</p>
<p><img alt="" src="_images/arm-delegate-runtime-build.svg" /></p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The <code class="docutils literal notranslate"><span class="pre">generate_pte_file</span></code> function in <code class="docutils literal notranslate"><span class="pre">run.sh</span></code> script produces the <code class="docutils literal notranslate"><span class="pre">.pte</span></code> files based on the models provided through <code class="docutils literal notranslate"><span class="pre">--model_name</span></code> input argument</p>
</div>
<div class="section" id="generating-executorch-libraries">
<h3>Generating ExecuTorch Libraries<a class="headerlink" href="#generating-executorch-libraries" title="Permalink to this heading">¶</a></h3>
<p>ExecuTorch’s CMake build system produces a set of build pieces which are critical to building the ExecuTorch runtime with-in the bare-metal environment you have for Corstone FVPs from Ethos-U SDK.</p>
<p><a class="reference internal" href="using-executorch-building-from-source.html"><span class="doc std std-doc">This</span></a> document provides a detailed overview of each individual build piece. For running either variant of the <code class="docutils literal notranslate"><span class="pre">.pte</span></code> file, you will need a core set of libraries. Here is a list,</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">libexecutorch.a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">libportable_kernels.a</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">libportable_ops_lib.a</span></code></p></li>
</ul>
<p>To run a <code class="docutils literal notranslate"><span class="pre">.pte</span></code> file with the Arm backend delegate call instructions, you will need the Arm backend delegate runtime library, that is,</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">libexecutorch_delegate_ethos_u.a</span></code></p></li>
</ul>
<p>These libraries are generated by the <code class="docutils literal notranslate"><span class="pre">backends/arm/scripts/build_executorch.sh</span></code>, <code class="docutils literal notranslate"><span class="pre">backends/arm/scripts/build_portable_kernels.sh</span></code> and <code class="docutils literal notranslate"><span class="pre">backends/arm/scripts/build_quantized_ops_aot_lib.sh</span></code> scripts called from the <code class="docutils literal notranslate"><span class="pre">run.sh</span></code> script.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">--portable_kernels</span></code> flag can be used to set the build flag <code class="docutils literal notranslate"><span class="pre">EXECUTORCH_SELECT_OPS_LIST</span></code> when running <code class="docutils literal notranslate"><span class="pre">backends/arm/scripts/build_portable_kernels.sh</span></code> that will decide the number of portable operators included in the build and are available at runtime. It must match with <code class="docutils literal notranslate"><span class="pre">.pte</span></code> file’s requirements, otherwise you will get <code class="docutils literal notranslate"><span class="pre">Missing</span> <span class="pre">Operator</span></code> error at runtime.</p>
<p>For example, there  in the command line above, to run SoftmaxModule, you only included the softmax CPU operator. Similarly, to run AddModule in a non-delegated manner you will need add op and so on. As you might have already realized, for the delegated operators, which will be executed by the Arm backend delegate, you do not need to include those operators in this list. This is only for <em>non-delegated</em> operators.</p>
</div>
<div class="section" id="building-the-executor-runner-bare-metal-application">
<h3>Building the executor_runner Bare-Metal Application<a class="headerlink" href="#building-the-executor-runner-bare-metal-application" title="Permalink to this heading">¶</a></h3>
<p>The SDK dir is the same one prepared <a class="reference internal" href="#setup-the-arm-ethos-u-software-development"><span class="std std-doc">earlier</span></a>. And, you will be passing the <code class="docutils literal notranslate"><span class="pre">.pte</span></code> file (any one of them) generated above.</p>
<p>Note, you have to generate a new <code class="docutils literal notranslate"><span class="pre">executor-runner</span></code> binary if you want to change the model or the <code class="docutils literal notranslate"><span class="pre">.pte</span></code> file. This constraint is from the constrained bare-metal runtime environment you have for Corstone-300/Corstone-320 platforms.</p>
<p>This is performed by the <code class="docutils literal notranslate"><span class="pre">backends/arm/scripts/build_executorch_runner.sh</span></code> script runned from <code class="docutils literal notranslate"><span class="pre">run.sh</span></code>.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The <code class="docutils literal notranslate"><span class="pre">run.sh</span></code> script takes in <code class="docutils literal notranslate"><span class="pre">--target</span></code> option, which provides a way to provide a specific target, Corstone-300(ethos-u55-128) or Corstone-320(ethos-u85-128)</p>
</div>
</div>
</div>
<div class="section" id="running-on-corstone-fvp-platforms">
<h2>Running on Corstone FVP Platforms<a class="headerlink" href="#running-on-corstone-fvp-platforms" title="Permalink to this heading">¶</a></h2>
<p>Once the elf is prepared, regardless of the <code class="docutils literal notranslate"><span class="pre">.pte</span></code> file variant is used to generate the bare metal elf. <code class="docutils literal notranslate"><span class="pre">run.sh</span></code> will run the FVP for you via the <code class="docutils literal notranslate"><span class="pre">backends/arm/scripts/run_fvp.sh</span></code> script but you can also run it directly.</p>
<p>The below command is used to run the <span class="xref myst">MV2Model</span> on Corstone-320 FVP</p>
<div class="highlight-none notranslate highlight-bash"><div class="highlight"><pre><span></span><span class="nv">ethos_u_build_dir</span><span class="o">=</span>examples/arm/executor_runner/

<span class="nv">elf</span><span class="o">=</span><span class="k">$(</span>find<span class="w"> </span><span class="si">${</span><span class="nv">ethos_u_build_dir</span><span class="si">}</span><span class="w"> </span>-name<span class="w"> </span><span class="s2">&quot;arm_executor_runner&quot;</span><span class="k">)</span>

FVP_Corstone_SSE-320_Ethos-U85<span class="w">                          </span><span class="se">\</span>
<span class="w">    </span>-C<span class="w"> </span>mps4_board.subsystem.ethosu.num_macs<span class="o">=</span><span class="m">128</span><span class="w">         </span><span class="se">\</span>
<span class="w">    </span>-C<span class="w"> </span>mps4_board.visualisation.disable-visualisation<span class="o">=</span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>-C<span class="w"> </span>vis_hdlcd.disable_visualisation<span class="o">=</span><span class="m">1</span><span class="w">                </span><span class="se">\</span>
<span class="w">    </span>-C<span class="w"> </span>mps4_board.telnetterminal0.start_telnet<span class="o">=</span><span class="m">0</span><span class="w">        </span><span class="se">\</span>
<span class="w">    </span>-C<span class="w"> </span>mps4_board.uart0.out_file<span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="w">                    </span><span class="se">\</span>
<span class="w">    </span>-C<span class="w"> </span>mps4_board.uart0.shutdown_on_eot<span class="o">=</span><span class="m">1</span><span class="w">               </span><span class="se">\</span>
<span class="w">    </span>-a<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">elf</span><span class="si">}</span><span class="s2">&quot;</span><span class="w">                                         </span><span class="se">\</span>
<span class="w">    </span>--timelimit<span class="w"> </span><span class="m">120</span><span class="w"> </span><span class="o">||</span><span class="w"> </span><span class="nb">true</span><span class="w"> </span><span class="c1"># seconds- after which sim will kill itself</span>
</pre></div>
</div>
<p>If successful, the simulator should produce something like the following on the shell,</p>
<div class="highlight-none notranslate highlight-console"><div class="highlight"><pre><span></span><span class="go">I [executorch:arm_executor_runner.cpp:364] Model in 0x70000000 $</span>
<span class="go">I [executorch:arm_executor_runner.cpp:366] Model PTE file loaded. Size: 4425968 bytes.</span>
<span class="go">I [executorch:arm_executor_runner.cpp:376] Model buffer loaded, has 1 methods</span>
<span class="go">I [executorch:arm_executor_runner.cpp:384] Running method forward</span>
<span class="go">I [executorch:arm_executor_runner.cpp:395] Setup Method allocator pool. Size: 62914560 bytes.</span>
<span class="go">I [executorch:arm_executor_runner.cpp:412] Setting up planned buffer 0, size 752640.</span>
<span class="go">I [executorch:ArmBackendEthosU.cpp:79] ArmBackend::init 0x70000070</span>
<span class="go">I [executorch:arm_executor_runner.cpp:445] Method loaded.</span>
<span class="go">I [executorch:arm_executor_runner.cpp:447] Preparing inputs...</span>
<span class="go">I [executorch:arm_executor_runner.cpp:461] Input prepared.</span>
<span class="go">I [executorch:arm_executor_runner.cpp:463] Starting the model execution...</span>
<span class="go">I [executorch:ArmBackendEthosU.cpp:118] ArmBackend::execute 0x70000070</span>
<span class="go">I [executorch:ArmBackendEthosU.cpp:298] Tensor input/output 0 will be permuted</span>
<span class="go">I [executorch:arm_perf_monitor.cpp:120] NPU Inferences : 1</span>
<span class="go">I [executorch:arm_perf_monitor.cpp:121] Profiler report, CPU cycles per operator:</span>
<span class="go">I [executorch:arm_perf_monitor.cpp:125] ethos-u : cycle_cnt : 1498202 cycles</span>
<span class="go">I [executorch:arm_perf_monitor.cpp:132] Operator(s) total: 1498202 CPU cycles</span>
<span class="go">I [executorch:arm_perf_monitor.cpp:138] Inference runtime: 6925114 CPU cycles total</span>
<span class="go">I [executorch:arm_perf_monitor.cpp:140] NOTE: CPU cycle values and ratio calculations require FPGA and identical CPU/NPU frequency</span>
<span class="go">I [executorch:arm_perf_monitor.cpp:149] Inference CPU ratio: 99.99 %</span>
<span class="go">I [executorch:arm_perf_monitor.cpp:153] Inference NPU ratio: 0.01 %</span>
<span class="go">I [executorch:arm_perf_monitor.cpp:162] cpu_wait_for_npu_cntr : 729 CPU cycles</span>
<span class="go">I [executorch:arm_perf_monitor.cpp:167] Ethos-U PMU report:</span>
<span class="go">I [executorch:arm_perf_monitor.cpp:168] ethosu_pmu_cycle_cntr : 5920305</span>
<span class="go">I [executorch:arm_perf_monitor.cpp:171] ethosu_pmu_cntr0 : 359921</span>
<span class="go">I [executorch:arm_perf_monitor.cpp:171] ethosu_pmu_cntr1 : 0</span>
<span class="go">I [executorch:arm_perf_monitor.cpp:171] ethosu_pmu_cntr2 : 0</span>
<span class="go">I [executorch:arm_perf_monitor.cpp:171] ethosu_pmu_cntr3 : 503</span>
<span class="go">I [executorch:arm_perf_monitor.cpp:178] Ethos-U PMU Events:[ETHOSU_PMU_EXT0_RD_DATA_BEAT_RECEIVED, ETHOSU_PMU_EXT1_RD_DATA_BEAT_RECEIVED, ETHOSU_PMU_EXT0_WR_DATA_BEAT_WRITTEN, ETHOSU_PMU_NPU_IDLE]</span>
<span class="go">I [executorch:arm_executor_runner.cpp:470] model_pte_loaded_size:     4425968 bytes.</span>
<span class="go">I [executorch:arm_executor_runner.cpp:484] method_allocator_used:     1355722 / 62914560  free: 61558838 ( used: 2 % )</span>
<span class="go">I [executorch:arm_executor_runner.cpp:491] method_allocator_planned:  752640 bytes</span>
<span class="go">I [executorch:arm_executor_runner.cpp:493] method_allocator_loaded:   966 bytes</span>
<span class="go">I [executorch:arm_executor_runner.cpp:494] method_allocator_input:    602116 bytes</span>
<span class="go">I [executorch:arm_executor_runner.cpp:495] method_allocator_executor: 0 bytes</span>
<span class="go">I [executorch:arm_executor_runner.cpp:498] temp_allocator_used:       0 / 1048576 free: 1048576 ( used: 0 % )</span>
<span class="go">I [executorch:arm_executor_runner.cpp:152] Model executed successfully.</span>
<span class="go">I [executorch:arm_executor_runner.cpp:156] 1 outputs:</span>
<span class="go">Output[0][0]: -0.749744</span>
<span class="go">Output[0][1]: -0.019224</span>
<span class="go">Output[0][2]: 0.134570</span>
<span class="go">...(Skipped)</span>
<span class="go">Output[0][996]: -0.230691</span>
<span class="go">Output[0][997]: -0.634399</span>
<span class="go">Output[0][998]: -0.115345</span>
<span class="go">Output[0][999]: 1.576386</span>
<span class="go">I [executorch:arm_executor_runner.cpp:177] Program complete, exiting.</span>
<span class="go">I [executorch:arm_executor_runner.cpp:179]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">run.sh</span></code> script provides various options to select a particular FVP target, use desired models, select portable kernels and can be explored using the <code class="docutils literal notranslate"><span class="pre">--help</span></code> argument</p>
</div>
</div>
<div class="section" id="takeaways">
<h2>Takeaways<a class="headerlink" href="#takeaways" title="Permalink to this heading">¶</a></h2>
<p>In this tutorial you have learnt how to use the ExecuTorch software to both export a standard model from PyTorch and to run it on the compact and fully functioned ExecuTorch runtime, enabling a smooth path for offloading models from PyTorch to Arm based platforms.</p>
<p>To recap, there are two major flows:</p>
<ul class="simple">
<li><p>A direct flow which offloads work onto the Cortex-M using libraries built into ExecuTorch.</p></li>
<li><p>A delegated flow which partitions the graph into sections for Cortex-M and sections which can be offloaded and accelerated on the Ethos-U hardware.</p></li>
</ul>
<p>Both of these flows continue to evolve, enabling more use-cases and better performance.</p>
</div>
<div class="section" id="faqs">
<h2>FAQs<a class="headerlink" href="#faqs" title="Permalink to this heading">¶</a></h2>
<!----
Describe what common errors users may see and how to resolve them.

* TODO - Binary size and operator Selection
* TODO - Cross-compilation targeting baremetal
* TODO - Debugging on FVP
----->
<p>If you encountered any bugs or issues following this tutorial please file a bug/issue here on <a class="reference external" href="https://github.com/pytorch/executorch/issues/new">Github</a>.</p>
</div>
</div>


             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2024, ExecuTorch.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>


        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Arm Ethos-U Backend</a><ul>
<li><a class="reference internal" href="#prerequisites">Prerequisites</a><ul>
<li><a class="reference internal" href="#hardware">Hardware</a></li>
<li><a class="reference internal" href="#software">Software</a></li>
</ul>
</li>
<li><a class="reference internal" href="#set-up-the-developer-environment">Set Up the Developer Environment</a><ul>
<li><a class="reference internal" href="#download-and-set-up-the-corstone-300-and-corstone-320-fvp">Download and Set Up the Corstone-300 and Corstone-320 FVP</a></li>
<li><a class="reference internal" href="#download-and-install-the-arm-gnu-aarch32-bare-metal-toolchain">Download and Install the Arm GNU AArch32 Bare-Metal Toolchain</a></li>
<li><a class="reference internal" href="#setup-the-arm-ethos-u-software-development">Setup the Arm Ethos-U Software Development</a></li>
<li><a class="reference internal" href="#install-the-vela-compiler">Install the Vela Compiler</a></li>
<li><a class="reference internal" href="#install-the-tosa-reference-model">Install the TOSA reference model</a></li>
<li><a class="reference internal" href="#notes">Notes:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#convert-the-pytorch-model-to-the-pte-file">Convert the PyTorch Model to the <code class="docutils literal notranslate"><span class="pre">.pte</span></code> File</a><ul>
<li><a class="reference internal" href="#pytorch-example-modules">PyTorch Example Modules</a><ul>
<li><a class="reference internal" href="#softmaxmodule">SoftmaxModule</a></li>
<li><a class="reference internal" href="#addmodule">AddModule</a></li>
<li><a class="reference internal" href="#mobilenetv2-module">MobileNetV2 Module</a></li>
</ul>
</li>
<li><a class="reference internal" href="#non-delegated-workflow">Non-delegated Workflow</a></li>
<li><a class="reference internal" href="#delegated-workflow">Delegated Workflow</a></li>
<li><a class="reference internal" href="#delegated-quantized-workflow">Delegated Quantized Workflow</a></li>
</ul>
</li>
<li><a class="reference internal" href="#getting-a-bare-metal-executable">Getting a Bare-Metal Executable</a><ul>
<li><a class="reference internal" href="#generating-executorch-libraries">Generating ExecuTorch Libraries</a></li>
<li><a class="reference internal" href="#building-the-executor-runner-bare-metal-application">Building the executor_runner Bare-Metal Application</a></li>
</ul>
</li>
<li><a class="reference internal" href="#running-on-corstone-fvp-platforms">Running on Corstone FVP Platforms</a></li>
<li><a class="reference internal" href="#takeaways">Takeaways</a></li>
<li><a class="reference internal" href="#faqs">FAQs</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/sphinx_highlight.js"></script>
         <script src="_static/clipboard.min.js"></script>
         <script src="_static/copybutton.js"></script>
         <script src="_static/design-tabs.js"></script>
         <script src="_static/js/progress-bar.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(false);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Introduction', 'Getting Started', 'Working with LLMs', 'Exporting to ExecuTorch',  'API Reference', 'IR Specification', 'Compiler Entry Points', 'Runtime', 'Quantization', 'Kernel Library', 'Native Delegates', 'Backend Delegates', 'SDK', 'Tutorials']
</script>

 
<script type="text/javascript">
// Handle the right navigation in third level pages. Without this
// in third level, only the last item always selected. This is a hacky
// way and we should revise it eventually.
// #side-scroll-highlight is disabled in .css.
// Get all menu items
var menuItems = document.querySelectorAll('.pytorch-right-menu a.reference.internal');
// Add a click event listener to each menu item
for (var i = 0; i < menuItems.length; i++) {
  menuItems[i].addEventListener('click', function(event) {
    // Remove the 'side-scroll-highlight-local' class from all menu items
    for (var j = 0; j < menuItems.length; j++) {
      menuItems[j].classList.remove('side-scroll-highlight-local');
    }
    // Add the 'side-scroll-highlight-local' class to the clicked item
    event.target.classList.add('side-scroll-highlight-local');
  });
}
</script>

 
<script type="text/javascript">
  $(document).ready(function () {
    // Patch links on interactive tutorial pages to point
    // to the correct ExecuTorch URLs.
    var downloadNote = $(".sphx-glr-download-link-note.admonition.note");
    if (downloadNote.length >= 1) {
      var tutorialUrl = $("#tutorial-type").text().substring($("#tutorial-type").text().indexOf("tutorials/") + 9); // 9 is the length of "tutorials/"
      var githubLink = "https://github.com/pytorch/executorch/blob/main/docs/source/tutorials_source" + tutorialUrl + ".py",
        notebookLink = $(".reference.download")[1].href,
        notebookDownloadPath = notebookLink.split('_downloads')[1],
        colabLink = "https://colab.research.google.com/github/pytorch/executorch/blob/gh-pages/main/_downloads" + notebookDownloadPath;

      $(".pytorch-call-to-action-links a[data-response='Run in Google Colab']").attr("href", colabLink);
      $(".pytorch-call-to-action-links a[data-response='View on Github']").attr("href", githubLink);
    }

    // Patch the "GitHub" link at the top of the page
    // to point to the ExecuTorch repo.
    var overwrite = function (_) {
      if ($(this).length > 0) {
        $(this)[0].href = "https://github.com/pytorch/executorch"
      }
    }
    // PC
    $(".main-menu a:contains('GitHub')").each(overwrite);
    // Overwrite link to Tutorials and Get Started top navigation. If these sections are moved
    // this overrides need to be updated.
    $(".main-menu a:contains('Tutorials')").attr("href", "https://pytorch.org/executorch/main/index#tutorials-and-examples");
    $(".main-menu a:contains('Get Started')").attr("href", "https://pytorch.org/executorch/main/getting-started-setup");
    // Mobile
    $(".mobile-menu a:contains('Github')").each(overwrite);
    // Overwrite link to Tutorials and Get Started top navigation. If these sections are moved
    // this overrides need to be updated.
    $(".mobile-menu a:contains('Tutorials')").attr("href", "https://pytorch.org/executorch/main/index#tutorials-and-examples");
    $(".mobile-menu a:contains('Get Started')").attr("href", "https://pytorch.org/executorch/main/getting-started-setup");

  });
</script>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2024</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
             <li>
               <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch Documentation</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
            <li>
               <a href="https://pytorch.org/newsletter">Newsletter</a>
             </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
            <li>
               <a href="https://pytorch.org/credits">Cloud Credit Program</a>
            </li>
            <li>
               <a href="https://pytorch.org/tac">Technical Advisory Council</a>
            </li>
            <li>
               <a href="https://pytorch.org/staff">Staff</a>
            </li>
            <li>
               <a href="https://pytorch.org/contact-us">Contact Us</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>